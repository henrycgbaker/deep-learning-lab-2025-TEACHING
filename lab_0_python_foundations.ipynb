{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Lab 0: Python Foundations for Deep Learning\n\n## Learning Objectives\n\nBy the end of this lab, you will be able to:\n1. Write type-annotated Python functions using modern syntax\n2. Apply Pythonic patterns (comprehensions, context managers, enumerate/zip)\n3. Perform NumPy array operations including broadcasting and reshaping\n4. Load, preprocess, and visualise data with Pandas and Matplotlib\n5. Understand OOP conventions used in PyTorch (classes, `__call__`, etc.)\n6. Implement linear regression using sklearn and from scratch\n7. Write generators for memory-efficient data processing\n\n## Prerequisites\n\n- Basic Python programming (variables, loops, functions, classes)\n- Familiarity with importing packages\n\n## Why This Lab?\n\nThis lab covers **all Python/ML foundations** needed before diving into deep learning:\n- **Type hints** make code self-documenting\n- **NumPy broadcasting** is essential for tensor operations\n- **Pandas** for data loading and preprocessing\n- **sklearn basics** bridge to neural network training\n- **OOP patterns** like `__call__` are central to `nn.Module`\n- **Generators** power PyTorch DataLoaders"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# ==== Environment Setup ====\nimport os\nimport sys\n\n# Detect environment\nIN_COLAB = 'google.colab' in sys.modules\n\nif IN_COLAB:\n    print(\"Running on Google Colab\")\nelse:\n    print(\"Running locally\")\n\ndef download_file(url: str, filename: str) -> str:\n    \"\"\"Download file if it doesn't exist. Works on both Colab and local.\"\"\"\n    if os.path.exists(filename):\n        print(f\"'{filename}' already exists\")\n        return filename\n    \n    print(f\"Downloading {filename}...\")\n    if IN_COLAB:\n        import subprocess\n        subprocess.run(['wget', '-q', url, '-O', filename], check=True)\n    else:\n        import urllib.request\n        urllib.request.urlretrieve(url, filename)\n    print(f\"Downloaded {filename}\")\n    return filename",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# ==== Device Setup ====\nimport torch\n\ndef get_device():\n    \"\"\"Get best available device: CUDA > MPS > CPU.\"\"\"\n    if torch.cuda.is_available():\n        device = torch.device('cuda')\n        print(f\"Using CUDA GPU: {torch.cuda.get_device_name(0)}\")\n    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n        device = torch.device('mps')\n        print(\"Using Apple MPS (Metal)\")\n    else:\n        device = torch.device('cpu')\n        print(\"Using CPU\")\n    return device\n\nDEVICE = get_device()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# Part 2: Python Foundations for Deep Learning\n\n---\n\n## 2.1 Type Hints\n\nType hints make code self-documenting and enable better IDE support.\n\n### Basic Syntax (Python 3.10+)"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Basic type hints\ndef greet(name: str) -> str:\n    return f\"Hello, {name}!\"\n\n# Collections - use lowercase (Python 3.10+)\ndef average(values: list[float]) -> float:\n    return sum(values) / len(values)\n\n# Dictionaries\ndef word_count(text: str) -> dict[str, int]:\n    words = text.lower().split()\n    return {word: words.count(word) for word in set(words)}\n\n# Optional values (can be None)\ndef find_index(items: list[str], target: str) -> int | None:\n    try:\n        return items.index(target)\n    except ValueError:\n        return None\n\n# Test\nprint(f\"greet('World'): {greet('World')}\")\nprint(f\"average([1, 2, 3, 4, 5]): {average([1, 2, 3, 4, 5])}\")\nprint(f\"word_count('the cat and the dog'): {word_count('the cat and the dog')}\")\nprint(f\"find_index(['a', 'b', 'c'], 'b'): {find_index(['a', 'b', 'c'], 'b')}\")\nprint(f\"find_index(['a', 'b', 'c'], 'x'): {find_index(['a', 'b', 'c'], 'x')}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary><b>Q: Why use `int | None` instead of `Optional[int]`?</b></summary>\n\n**A:** `int | None` is the modern Python 3.10+ syntax. It's more readable and doesn't require importing from `typing`. The older `Optional[int]` still works but is more verbose.\n\n```python\n# Old style (pre-3.10)\nfrom typing import Optional, List\ndef f(x: Optional[int]) -> List[str]: ...\n\n# Modern style (3.10+)\ndef f(x: int | None) -> list[str]: ...\n```\n</details>"
  },
  {
   "cell_type": "markdown",
   "source": "### Exercise: Add Type Hints\n\nAdd type hints to the following functions:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Exercise: Add type hints to these functions\n\ndef calculate_loss(predictions, targets):\n    \"\"\"Calculate mean squared error loss.\"\"\"\n    return sum((p - t) ** 2 for p, t in zip(predictions, targets)) / len(predictions)\n\ndef get_batch(data, batch_idx, batch_size):\n    \"\"\"Get a batch from data. Returns None if batch_idx out of range.\"\"\"\n    start = batch_idx * batch_size\n    if start >= len(data):\n        return None\n    return data[start:start + batch_size]\n\ndef create_optimiser_config(lr, momentum, weight_decay):\n    \"\"\"Create optimiser configuration dictionary.\"\"\"\n    return {\"lr\": lr, \"momentum\": momentum, \"weight_decay\": weight_decay}\n\n# Test (uncomment after adding hints):\n# print(calculate_loss([1.0, 2.0], [1.1, 2.2]))\n# print(get_batch([1,2,3,4,5], 0, 2))\n# print(create_optimiser_config(0.01, 0.9, 1e-4))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary><b>Solution: Type Hints</b></summary>\n\n```python\ndef calculate_loss(predictions: list[float], targets: list[float]) -> float:\n    \"\"\"Calculate mean squared error loss.\"\"\"\n    return sum((p - t) ** 2 for p, t in zip(predictions, targets)) / len(predictions)\n\ndef get_batch(data: list, batch_idx: int, batch_size: int) -> list | None:\n    \"\"\"Get a batch from data. Returns None if batch_idx out of range.\"\"\"\n    start = batch_idx * batch_size\n    if start >= len(data):\n        return None\n    return data[start:start + batch_size]\n\ndef create_optimiser_config(lr: float, momentum: float, weight_decay: float) -> dict[str, float]:\n    \"\"\"Create optimiser configuration dictionary.\"\"\"\n    return {\"lr\": lr, \"momentum\": momentum, \"weight_decay\": weight_decay}\n```\n</details>"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2.2 Docstrings\n\nUse Google-style docstrings for complex functions:"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "def train_model(\n    model,\n    train_loader,\n    epochs: int = 10,\n    learning_rate: float = 0.001,\n    verbose: bool = True\n) -> dict[str, list[float]]:\n    \"\"\"\n    Train a PyTorch model.\n    \n    Args:\n        model: PyTorch model to train (nn.Module)\n        train_loader: DataLoader with training data\n        epochs: Number of training epochs\n        learning_rate: Learning rate for optimiser\n        verbose: Whether to print progress\n    \n    Returns:\n        Dictionary with 'train_loss' history\n    \n    Raises:\n        ValueError: If epochs < 1\n    \n    Example:\n        >>> history = train_model(model, loader, epochs=5)\n        >>> plt.plot(history['train_loss'])\n    \"\"\"\n    if epochs < 1:\n        raise ValueError(\"epochs must be >= 1\")\n    # ... training code ...\n    return {\"train_loss\": []}\n\n# For simple/obvious functions, a one-liner is fine:\ndef relu(x: float) -> float:\n    \"\"\"Return max(0, x).\"\"\"\n    return max(0, x)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2.3 Pythonic Patterns\n\n### List Comprehensions"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Instead of:\nsquares_loop = []\nfor i in range(10):\n    squares_loop.append(i ** 2)\n\n# Use:\nsquares = [i ** 2 for i in range(10)]\nprint(f\"Squares: {squares}\")\n\n# With condition\nevens = [i for i in range(20) if i % 2 == 0]\nprint(f\"Evens: {evens}\")\n\n# Dict comprehension\nword_lengths = {word: len(word) for word in [\"cat\", \"elephant\", \"dog\"]}\nprint(f\"Word lengths: {word_lengths}\")\n\n# Set comprehension (removes duplicates)\nunique_lengths = {len(word) for word in [\"cat\", \"bat\", \"elephant\", \"ant\"]}\nprint(f\"Unique lengths: {unique_lengths}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### enumerate, zip, sorted"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# enumerate - get index and value\nfruits = [\"apple\", \"banana\", \"cherry\"]\nfor i, fruit in enumerate(fruits):\n    print(f\"{i}: {fruit}\")\n\n# zip - iterate multiple sequences together\nnames = [\"Alice\", \"Bob\", \"Charlie\"]\nscores = [85, 92, 78]\nfor name, score in zip(names, scores):\n    print(f\"{name}: {score}\")\n\n# sorted with key function\nstudents = [(\"Alice\", 85), (\"Bob\", 92), (\"Charlie\", 78)]\nby_score = sorted(students, key=lambda x: x[1], reverse=True)\nprint(f\"By score (desc): {by_score}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary><b>Q: When should you use a list comprehension vs a regular loop?</b></summary>\n\n**A:** Use comprehensions when:\n- Building a new list/dict/set from an iterable\n- The logic fits on one readable line\n\nUse regular loops when:\n- You need complex logic or multiple statements\n- You're modifying in place rather than creating new\n- Readability suffers from one-liner\n\n**Rule of thumb:** If you can't understand it in 5 seconds, use a loop.\n</details>"
  },
  {
   "cell_type": "markdown",
   "source": "### Exercise: Pythonic Refactoring\n\nRefactor this verbose code to use Pythonic patterns:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# VERBOSE VERSION - refactor this to be Pythonic!\n\n# Task 1: Create list of (name, score) tuples where score > 80\nnames = [\"Alice\", \"Bob\", \"Charlie\", \"Diana\"]\nscores = [95, 72, 88, 65]\nhigh_scorers = []\nfor i in range(len(names)):\n    if scores[i] > 80:\n        high_scorers.append((names[i], scores[i]))\n\n# Task 2: Create dict mapping filename -> extension\nfiles = [\"data.csv\", \"model.pt\", \"config.json\", \"README.md\"]\nextensions = {}\nfor f in files:\n    parts = f.split(\".\")\n    name = parts[0]\n    ext = parts[1]\n    extensions[name] = ext\n\n# Task 3: Read file, count non-empty lines (use context manager!)\nf = open(\"test_file.txt\", \"w\")\nf.write(\"line1\\n\\nline2\\nline3\\n\")\nf.close()\n\nf = open(\"test_file.txt\", \"r\")\nlines = f.readlines()\nf.close()\ncount = 0\nfor line in lines:\n    if line.strip() != \"\":\n        count = count + 1\n\n# Cleanup\nimport os\nos.remove(\"test_file.txt\")\n\nprint(f\"High scorers: {high_scorers}\")\nprint(f\"Extensions: {extensions}\")\nprint(f\"Non-empty lines: {count}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<details>\n<summary><b>Solution: Pythonic Refactoring</b></summary>\n\n```python\n# Task 1: zip + list comprehension with filter\nhigh_scorers = [(n, s) for n, s in zip(names, scores) if s > 80]\n\n# Task 2: dict comprehension with split unpacking\nextensions = {f.split(\".\")[0]: f.split(\".\")[1] for f in files}\n# Or cleaner:\nextensions = {Path(f).stem: Path(f).suffix[1:] for f in files}\n\n# Task 3: context manager + sum with generator\nwith open(\"test_file.txt\", \"w\") as f:\n    f.write(\"line1\\n\\nline2\\nline3\\n\")\n\nwith open(\"test_file.txt\", \"r\") as f:\n    count = sum(1 for line in f if line.strip())\n```\n</details>",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Context Managers"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Context managers ensure cleanup (files close, locks release, etc.)\n\n# File I/O - always use 'with'\nfrom pathlib import Path\n\n# Write\nwith open(\"test.txt\", \"w\") as f:\n    f.write(\"Hello, World!\")\n\n# Read\nwith open(\"test.txt\", \"r\") as f:\n    content = f.read()\nprint(f\"File content: {content}\")\n\n# Clean up\nPath(\"test.txt\").unlink()\n\n# PyTorch example: disable gradients for inference\nimport torch\nx = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n\nwith torch.no_grad():\n    y = x * 2  # No gradient tracking here\nprint(f\"y.requires_grad: {y.requires_grad}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Basic try/except\ndef safe_divide(a: float, b: float) -> float | None:\n    try:\n        return a / b\n    except ZeroDivisionError:\n        print(\"Warning: Division by zero\")\n        return None\n\nprint(safe_divide(10, 2))\nprint(safe_divide(10, 0))\n\n# Multiple exception types with proper chaining\ndef parse_int(s: str) -> int:\n    try:\n        return int(s)\n    except ValueError as e:\n        raise ValueError(f\"Cannot parse '{s}' as integer\") from e  # Chain exceptions!\n    except TypeError as e:\n        raise TypeError(f\"Expected string, got {type(s)}\") from e\n\n# finally - always runs (cleanup)\ndef read_with_cleanup(filename: str) -> str:\n    f = None\n    try:\n        f = open(filename, \"r\")\n        return f.read()\n    except FileNotFoundError:\n        return \"\"\n    finally:\n        if f:\n            f.close()\n            print(\"File closed\")\n\n# Demo exception chaining\ntry:\n    parse_int(\"abc\")\nexcept ValueError as e:\n    print(f\"Caught: {e}\")\n    print(f\"Original cause: {e.__cause__}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary><b>Q: When should you catch exceptions vs let them propagate?</b></summary>\n\n**A:** \n- **Catch** when you can handle it meaningfully (retry, default value, cleanup)\n- **Propagate** when the caller should decide how to handle it\n\n**Bad:** Catching everything and hiding errors\n```python\ntry:\n    result = do_something()\nexcept:  # Never do this!\n    pass\n```\n\n**Good:** Catch specific exceptions you can handle\n```python\ntry:\n    data = load_file(path)\nexcept FileNotFoundError:\n    data = default_data\n```\n</details>"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Part 2 Key Takeaways\n\n- **Type hints** (`def f(x: int) -> str`) improve code clarity and IDE support\n- **Comprehensions** are cleaner than loops for building collections\n- **Context managers** (`with`) ensure proper resource cleanup\n- **Exception chaining** (`raise ... from e`) preserves the original error"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# Part 3: NumPy Essentials\n\nNumPy is the foundation for all deep learning frameworks. Understanding it is essential.\n\n---\n\n## 3.1 Why NumPy Matters for Deep Learning"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import numpy as np\nimport time\n\n# Vectorisation is MUCH faster than loops\nsize = 1_000_000\n\n# Loop version\na_list = list(range(size))\nb_list = list(range(size))\n\nstart = time.time()\nc_list = [a + b for a, b in zip(a_list, b_list)]\nloop_time = time.time() - start\n\n# NumPy version\na_np = np.arange(size)\nb_np = np.arange(size)\n\nstart = time.time()\nc_np = a_np + b_np\nnumpy_time = time.time() - start\n\nprint(f\"Loop time: {loop_time:.4f}s\")\nprint(f\"NumPy time: {numpy_time:.4f}s\")\nprint(f\"NumPy is {loop_time/numpy_time:.1f}x faster\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "<details>\n<summary><b>Deep Dive: Why is NumPy so fast?</b></summary>\n\nNumPy achieves 10-100x speedups through several mechanisms:\n\n1. **Contiguous Memory Layout**: Arrays store data in continuous memory blocks, enabling efficient CPU cache utilisation. Python lists store pointers to scattered objects.\n\n2. **Compiled C/Fortran Backend**: Core operations are implemented in optimised C code, not interpreted Python.\n\n3. **SIMD Vectorisation**: Modern CPUs can process multiple numbers per instruction (Single Instruction, Multiple Data). NumPy operations leverage this automatically.\n\n4. **No Type Checking Per Element**: Python lists check types dynamically for each element. NumPy arrays have uniform dtype - no per-element overhead.\n\n5. **No Python Object Overhead**: Each Python object has ~28 bytes of overhead (reference count, type pointer, etc.). NumPy stores raw numbers.\n\n```python\n# Memory comparison\nimport sys\npy_list = [1.0] * 1000\nnp_array = np.ones(1000)\nprint(f\"Python list: {sys.getsizeof(py_list) + sum(sys.getsizeof(x) for x in py_list)} bytes\")\nprint(f\"NumPy array: {np_array.nbytes} bytes\")  # Just 8000 bytes (8 bytes per float64)\n```\n\n**Rule**: If you're looping over array elements in Python, you're probably doing it wrong.\n</details>",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3.2 Array Creation & Indexing"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import numpy as np\n\n# Creating arrays\na = np.array([1, 2, 3, 4, 5])          # From list\nb = np.zeros((3, 4))                     # 3x4 zeros\nc = np.ones((2, 3))                      # 2x3 ones\nd = np.arange(0, 10, 2)                  # [0, 2, 4, 6, 8]\ne = np.linspace(0, 1, 5)                 # 5 points from 0 to 1\nf = np.random.randn(3, 3)                # 3x3 standard normal\n\nprint(f\"zeros shape: {b.shape}\")\nprint(f\"arange: {d}\")\nprint(f\"linspace: {e}\")\n\n# Indexing\narr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nprint(f\"\\narr:\\n{arr}\")\nprint(f\"arr[0, 1]: {arr[0, 1]}\")         # Single element\nprint(f\"arr[0, :]: {arr[0, :]}\")         # First row\nprint(f\"arr[:, 1]: {arr[:, 1]}\")         # Second column\nprint(f\"arr[0:2, 1:3]:\\n{arr[0:2, 1:3]}\")  # Subarray\n\n# Boolean indexing\nprint(f\"\\narr > 5: {arr[arr > 5]}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3.3 Broadcasting\n\nBroadcasting allows operations between arrays of different shapes.\n\n### Rules:\n1. Compare shapes from right to left\n2. Dimensions match if they're equal OR one of them is 1\n3. Missing dimensions are treated as 1\n\n**Before running each cell below, predict the output shape!**"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import numpy as np\n\n# Scalar broadcasts to any shape\na = np.array([[1, 2, 3], [4, 5, 6]])  # Shape: (2, 3)\nprint(f\"a + 10:\\n{a + 10}\")  # 10 broadcasts to (2, 3)\n\n# Row vector broadcasts across rows\nrow = np.array([100, 200, 300])  # Shape: (3,)\nprint(f\"\\na + row:\\n{a + row}\")  # (3,) -> (2, 3)\n\n# Column vector broadcasts across columns\ncol = np.array([[10], [20]])  # Shape: (2, 1)\nprint(f\"\\na + col:\\n{a + col}\")  # (2, 1) -> (2, 3)\n\n# Outer product via broadcasting\nx = np.array([1, 2, 3])[:, np.newaxis]  # Shape: (3, 1)\ny = np.array([10, 20])                   # Shape: (2,)\nprint(f\"\\nOuter product (x * y):\\n{x * y}\")  # (3, 1) * (2,) -> (3, 2)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary><b>Q: Why does `np.array([1,2]) + np.array([[1],[2],[3]])` work?</b></summary>\n\n**A:** Let's trace the broadcasting:\n- Left: shape (2,)\n- Right: shape (3, 1)\n\nAlign from right:\n```\n     (2,)  ->  (1, 2)  [add dimension]\n  (3, 1)   ->  (3, 1)\n  Result:      (3, 2)  [both expand]\n```\n\nEach expands where it has size 1:\n```python\n[[1, 2],      [[1, 1],     [[2, 3],\n [1, 2],  +    [2, 2],  =   [3, 4],\n [1, 2]]       [3, 3]]      [4, 5]]\n```\n</details>"
  },
  {
   "cell_type": "code",
   "source": "# Broadcasting Debugger - useful helper function\ndef broadcast_shapes(*shapes):\n    \"\"\"Visualise how shapes align and what the result will be.\"\"\"\n    max_dims = max(len(s) for s in shapes)\n    \n    # Pad shapes with 1s on the left\n    padded = [((1,) * (max_dims - len(s))) + s for s in shapes]\n    \n    print(\"Shape alignment (right-aligned):\")\n    for i, (orig, pad) in enumerate(zip(shapes, padded)):\n        print(f\"  Array {i+1}: {str(orig):>15} -> {pad}\")\n    \n    # Compute result shape\n    result = []\n    for dims in zip(*padded):\n        if len(set(d for d in dims if d != 1)) > 1:\n            print(f\"\\n\u274c INCOMPATIBLE: dimension has {dims} (multiple non-1 values)\")\n            return None\n        result.append(max(dims))\n    \n    print(f\"\\n\u2713 Result shape: {tuple(result)}\")\n    return tuple(result)\n\n# Test it\nprint(\"Example 1: (2,3) + (3,)\")\nbroadcast_shapes((2, 3), (3,))\n\nprint(\"\\nExample 2: (3,1) + (1,4)\")\nbroadcast_shapes((3, 1), (1, 4))\n\nprint(\"\\nExample 3: Incompatible shapes\")\nbroadcast_shapes((3, 4), (5,))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Exercise: Broadcasting\n\nFix the code to add bias to each sample:"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import numpy as np\n\n# Data: 100 samples, 784 features (like MNIST flattened)\nX = np.random.randn(100, 784)\nbias = np.random.randn(784)\n\n# This should add bias to each row\nresult = X + bias  # Does this work?\nprint(f\"X shape: {X.shape}\")\nprint(f\"bias shape: {bias.shape}\")\nprint(f\"result shape: {result.shape}\")\nassert result.shape == (100, 784), \"Shape mismatch!\"\nprint(\"Broadcasting worked!\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary><b>Solution: Broadcasting</b></summary>\n\nThe code already works! Broadcasting automatically handles this case:\n\n```python\nX.shape     # (100, 784)\nbias.shape  # (784,)\n\n# NumPy aligns from right:\n#   X:    (100, 784)\n#   bias:      (784,)  \u2192 treated as (1, 784)\n# Result: (100, 784) \u2713\n```\n\nIf bias had shape `(100,)` instead, you'd need to reshape:\n```python\nbias_wrong = np.random.randn(100)  # Shape (100,)\nresult = X + bias_wrong[:, np.newaxis]  # Reshape to (100, 1) for column broadcast\n```\n</details>"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3.4 Common Operations"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import numpy as np\n\na = np.array([[1, 2, 3], [4, 5, 6]])\nprint(f\"Original shape: {a.shape}\")\n\n# Reshape\nb = a.reshape(3, 2)\nprint(f\"Reshaped to (3,2):\\n{b}\")\n\n# Transpose\nprint(f\"Transposed:\\n{a.T}\")\n\n# Flatten\nprint(f\"Flattened: {a.flatten()}\")\n\n# Concatenate\nc = np.array([[7, 8, 9]])\nprint(f\"\\nVertical concat:\\n{np.concatenate([a, c], axis=0)}\")\n\nd = np.array([[10], [20]])\nprint(f\"\\nHorizontal concat:\\n{np.concatenate([a, d], axis=1)}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Reductions along axes\na = np.array([[1, 2, 3], [4, 5, 6]])\nprint(f\"Array:\\n{a}\")\n\nprint(f\"\\nSum all: {a.sum()}\")\nprint(f\"Sum rows (axis=1): {a.sum(axis=1)}\")     # Sum each row\nprint(f\"Sum cols (axis=0): {a.sum(axis=0)}\")     # Sum each column\n\nprint(f\"\\nMean all: {a.mean():.2f}\")\nprint(f\"Mean rows: {a.mean(axis=1)}\")\n\n# Matrix multiplication\nW = np.random.randn(3, 4)  # 3x4\nx = np.random.randn(4, 2)  # 4x2\ny = W @ x                   # 3x2\nprint(f\"\\nW @ x: {W.shape} @ {x.shape} = {y.shape}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary><b>Q: What's the difference between `axis=0` and `axis=1` in reductions?</b></summary>\n\n**A:** The axis parameter specifies which dimension to \"collapse\":\n- `axis=0`: Collapse rows \u2192 result has shape of a single row\n- `axis=1`: Collapse columns \u2192 result has shape of a single column\n\nThink of it as: \"sum **along** this axis\" or \"reduce **this** dimension\"\n\n```python\na = [[1, 2, 3],\n     [4, 5, 6]]  # Shape (2, 3)\n\na.sum(axis=0)  # [5, 7, 9]   - summed down columns, shape (3,)\na.sum(axis=1)  # [6, 15]     - summed across rows, shape (2,)\n```\n</details>"
  },
  {
   "cell_type": "markdown",
   "source": "### Exercise: Shape Prediction\n\n**Predict the output shapes before running!** Write your predictions, then verify.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import numpy as np\n\n# VIEWS: Slicing creates a view (shares memory!)\noriginal = np.array([1, 2, 3, 4, 5])\nview = original[1:4]  # This is a VIEW\n\nprint(f\"Original: {original}\")\nprint(f\"View: {view}\")\n\n# Modifying the view changes the original!\nview[0] = 999\nprint(f\"After modifying view[0]:\")\nprint(f\"  Original: {original}\")  # Also changed!\nprint(f\"  View: {view}\")\n\n# COPIES: Use .copy() to get independent data\noriginal = np.array([1, 2, 3, 4, 5])\ncopy = original[1:4].copy()  # Explicit copy\n\ncopy[0] = 999\nprint(f\"\\nWith .copy():\")\nprint(f\"  Original: {original}\")  # Unchanged!\nprint(f\"  Copy: {copy}\")\n\n# How to check: views share memory\na = np.array([1, 2, 3])\nb = a[:]      # View\nc = a.copy()  # Copy\n\nprint(f\"\\nShares memory?\")\nprint(f\"  a and b: {np.shares_memory(a, b)}\")  # True\nprint(f\"  a and c: {np.shares_memory(a, c)}\")  # False",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<details>\n<summary><b>Q: Is `arr.reshape(3, 4)` a view or a copy?</b></summary>\n\n**A:** It depends! Reshape returns a **view** when possible (if the data is contiguous in memory), but may return a **copy** if the memory layout doesn't allow a view.\n\n```python\na = np.arange(12).reshape(3, 4)  # Usually a view\nb = a.T.reshape(6, 2)            # Must be a copy (transpose breaks contiguity)\n```\n\n**Safe approach:** If you need to be sure, use `.copy()` explicitly. If you want to ensure a view (and error otherwise), use `.reshape()` with `order='A'` or `np.ndarray.view()`.\n</details>",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## 3.5 Views vs Copies (Critical!)\n\nUnderstanding when NumPy creates a view vs a copy prevents subtle bugs.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Part 3 Key Takeaways\n\n- **Vectorise** operations\u2014loops over arrays are slow\n- **Broadcasting** aligns shapes from the right, expanding size-1 dimensions\n- **Views** share memory with originals; use `.copy()` for independence\n- **axis=0** collapses rows, **axis=1** collapses columns"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# Part 4: Data Handling with Pandas\n\nPandas is the standard library for tabular data in Python. Essential for loading and preprocessing ML datasets.\n\n---\n\n## 4.1 Loading Data"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import pandas as pd\nimport numpy as np\nfrom sklearn.datasets import load_iris, load_wine\n\n# Load from sklearn\niris = load_iris(as_frame=True)\ndf = iris['data']\ntarget = iris['target']\n\nprint(f\"Shape: {df.shape}\")\nprint(f\"Columns: {list(df.columns)}\")\ndf.head()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4.2 DataFrame Basics"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Filtering\nshort_sepals = df[df['sepal length (cm)'] < 5]\nprint(f\"Flowers with sepal < 5cm: {len(short_sepals)}\")\n\n# Selecting columns\nsubset = df[['sepal length (cm)', 'petal length (cm)']]\nprint(f\"Subset shape: {subset.shape}\")\n\n# Adding columns\ndf_with_target = df.copy()\ndf_with_target['species'] = target\ndf_with_target['species_name'] = df_with_target['species'].map({0: 'setosa', 1: 'versicolour', 2: 'virginica'})\n\n# GroupBy\nprint(\"\\nMean by species:\")\nprint(df_with_target.groupby('species_name')[['sepal length (cm)', 'petal length (cm)']].mean())",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary><b>Q: What's the difference between `df[col]` and `df[[col]]`?</b></summary>\n\n**A:** \n- `df['col']` returns a **Series** (1D)\n- `df[['col']]` returns a **DataFrame** (2D, single column)\n\n```python\ntype(df['sepal length (cm)'])  # pandas.Series\ntype(df[['sepal length (cm)']])  # pandas.DataFrame\n```\n\nUse double brackets when you need to keep the DataFrame structure (e.g., for sklearn).\n</details>"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4.3 Handling Missing Values"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Create sample data with missing values\ndf_missing = pd.DataFrame({\n    'A': [1, 2, np.nan, 4, 5],\n    'B': [np.nan, 2, 3, np.nan, 5],\n    'C': [1, 2, 3, 4, 5]\n})\n\nprint(\"Original:\")\nprint(df_missing)\nprint(f\"\\nMissing values per column:\\n{df_missing.isna().sum()}\")\n\n# Option 1: Drop rows with any NaN\nprint(f\"\\nAfter dropna(): {len(df_missing.dropna())} rows\")\n\n# Option 2: Fill with value\nprint(f\"\\nFill with 0:\\n{df_missing.fillna(0)}\")\n\n# Option 3: Fill with column mean\nprint(f\"\\nFill with mean:\\n{df_missing.fillna(df_missing.mean())}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4.4 Encoding Categorical Variables"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# One-hot encoding with pandas\ndf_categories = pd.DataFrame({\n    'colour': ['red', 'blue', 'green', 'red', 'blue'],\n    'size': ['S', 'M', 'L', 'M', 'S']\n})\n\nprint(\"Original:\")\nprint(df_categories)\n\n# One-hot encode\nencoded = pd.get_dummies(df_categories, columns=['colour', 'size'])\nprint(\"\\nOne-hot encoded:\")\nprint(encoded)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4.5 Feature Scaling"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n\n# Sample data\nX = np.array([[1, 100], [2, 200], [3, 300], [4, 400]])\n\n# StandardScaler: zero mean, unit variance\nscaler_std = StandardScaler()\nX_standardised = scaler_std.fit_transform(X)\nprint(\"StandardScaler (mean=0, std=1):\")\nprint(X_standardised)\nprint(f\"Mean: {X_standardised.mean(axis=0)}, Std: {X_standardised.std(axis=0)}\")\n\n# MinMaxScaler: scale to [0, 1]\nscaler_mm = MinMaxScaler()\nX_minmax = scaler_mm.fit_transform(X)\nprint(\"\\nMinMaxScaler [0, 1]:\")\nprint(X_minmax)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary><b>Q: When should you use StandardScaler vs MinMaxScaler?</b></summary>\n\n**A:**\n- **StandardScaler**: When features follow roughly Gaussian distribution. Works well with most ML algorithms, especially those sensitive to feature magnitudes (SVM, logistic regression, neural networks).\n\n- **MinMaxScaler**: When you need bounded values (e.g., [0,1] for image pixels or probabilities). Sensitive to outliers - a single extreme value can compress all other values.\n\n**Rule of thumb**: Start with StandardScaler for neural networks. Use MinMaxScaler when interpretability of the scale matters.\n</details>"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Part 4 Key Takeaways\n\n- **pandas** is essential for loading and exploring tabular data\n- Always check for **missing values** before training\n- **One-hot encoding** converts categories to numeric features\n- **Scaling** (StandardScaler/MinMaxScaler) improves model training"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# Part 5: Visualisation with Matplotlib\n\nVisualisation is critical for understanding data and debugging models.\n\n---\n\n## 5.1 Basic Plots"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import matplotlib.pyplot as plt\n\n# Reload iris for plotting\niris = load_iris(as_frame=True)\ndf = iris['data']\ntarget = iris['target']\n\n# Scatter plot with colour by class\nfig, axes = plt.subplots(1, 2, figsize=(12, 4))\n\n# Left: Sepal dimensions\ncolours = ['red', 'green', 'blue']\nfor i, species in enumerate(['setosa', 'versicolour', 'virginica']):\n    mask = target == i\n    axes[0].scatter(df.loc[mask, 'sepal length (cm)'], \n                   df.loc[mask, 'sepal width (cm)'],\n                   c=colours[i], label=species, alpha=0.7)\naxes[0].set_xlabel('Sepal Length (cm)')\naxes[0].set_ylabel('Sepal Width (cm)')\naxes[0].set_title('Sepal Dimensions')\naxes[0].legend()\n\n# Right: Petal dimensions\nfor i, species in enumerate(['setosa', 'versicolour', 'virginica']):\n    mask = target == i\n    axes[1].scatter(df.loc[mask, 'petal length (cm)'], \n                   df.loc[mask, 'petal width (cm)'],\n                   c=colours[i], label=species, alpha=0.7)\naxes[1].set_xlabel('Petal Length (cm)')\naxes[1].set_ylabel('Petal Width (cm)')\naxes[1].set_title('Petal Dimensions')\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5.2 Histograms and Distributions"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Histogram of features\nfig, axes = plt.subplots(2, 2, figsize=(10, 8))\naxes = axes.flatten()\n\nfor i, col in enumerate(df.columns):\n    axes[i].hist(df[col], bins=20, edgecolour='black', alpha=0.7)\n    axes[i].set_xlabel(col)\n    axes[i].set_ylabel('Frequency')\n    axes[i].set_title(f'Distribution of {col}')\n\nplt.tight_layout()\nplt.show()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5.3 Plotting for Deep Learning\n\nCommon plots you'll use when training models:"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Simulated training history\nepochs = range(1, 51)\ntrain_loss = 2.0 * np.exp(-np.array(epochs) / 10) + 0.1 + np.random.randn(50) * 0.05\nval_loss = 2.0 * np.exp(-np.array(epochs) / 12) + 0.15 + np.random.randn(50) * 0.08\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 4))\n\n# Loss curves\naxes[0].plot(epochs, train_loss, label='Train Loss', colour='blue')\naxes[0].plot(epochs, val_loss, label='Val Loss', colour='orange')\naxes[0].set_xlabel('Epoch')\naxes[0].set_ylabel('Loss')\naxes[0].set_title('Training Curves')\naxes[0].legend()\naxes[0].grid(True, alpha=0.3)\n\n# Gradient histogram (simulated)\ngradients = np.random.randn(1000) * 0.1\naxes[1].hist(gradients, bins=50, edgecolour='black', alpha=0.7)\naxes[1].axvline(x=0, colour='red', linestyle='--', label='Zero')\naxes[1].set_xlabel('Gradient Value')\naxes[1].set_ylabel('Frequency')\naxes[1].set_title('Gradient Distribution (Healthy)')\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Tip: If gradients cluster near 0 -> vanishing gradients\")\nprint(\"     If gradients are huge -> exploding gradients\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary><b>Q: What does a bimodal gradient histogram suggest?</b></summary>\n\n**A:** A bimodal (two-peaked) gradient histogram often indicates:\n1. Different layers learning at different rates\n2. Potential issues with initialisation\n3. Some weights updating much faster than others\n\nHealthy gradient distributions are typically unimodal and centred near zero.\n</details>\n\n<details>\n<summary><b>Q: What should you look for in training curves?</b></summary>\n\n**A:** Key patterns to watch:\n- **Train loss decreasing, val loss stable then increasing** \u2192 Overfitting, stop earlier\n- **Both losses plateau high** \u2192 Underfitting, increase model capacity\n- **Loss spikes or oscillates** \u2192 Learning rate too high\n- **Very slow decrease** \u2192 Learning rate too low\n- **Train and val loss track closely** \u2192 Good generalisation\n</details>"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# Part 6: OOP for Deep Learning\n\nPyTorch heavily uses OOP. Understanding these patterns is essential.\n\n---\n\n## 6.1 Classes Review"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Part 5 Key Takeaways\n\n- **Scatter plots** reveal feature relationships and class separability\n- **Histograms** show feature distributions\n- **Training curves** diagnose overfitting, underfitting, and learning rate issues\n- **Gradient histograms** detect vanishing/exploding gradients"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "class NeuralNetwork:\n    \"\"\"A simple neural network class demonstrating OOP patterns.\"\"\"\n    \n    # Class attribute (shared by all instances)\n    default_activation = \"relu\"\n    \n    def __init__(self, input_size: int, hidden_size: int, output_size: int):\n        \"\"\"Initialise the network.\"\"\"\n        # Instance attributes (unique to each instance)\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.output_size = output_size\n        \n        # Simulated weights\n        self.weights = {\n            \"W1\": np.random.randn(input_size, hidden_size) * 0.01,\n            \"W2\": np.random.randn(hidden_size, output_size) * 0.01,\n        }\n    \n    def forward(self, x: np.ndarray) -> np.ndarray:\n        \"\"\"Forward pass.\"\"\"\n        h = x @ self.weights[\"W1\"]\n        h = np.maximum(0, h)  # ReLU\n        return h @ self.weights[\"W2\"]\n\n# Usage\nnet = NeuralNetwork(784, 128, 10)\nx = np.random.randn(32, 784)  # Batch of 32\noutput = net.forward(x)\nprint(f\"Input: {x.shape} -> Output: {output.shape}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6.2 Naming Conventions"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "class DataProcessor:\n    \"\"\"Demonstrates Python naming conventions.\"\"\"\n    \n    def __init__(self, data: list):\n        self.data = data              # Public: anyone can access\n        self._cache = {}              # Protected: internal use, but accessible\n        self.__secret = \"hidden\"      # Private: name-mangled to _DataProcessor__secret\n    \n    def process(self):\n        \"\"\"Public method - part of the API.\"\"\"\n        return self._preprocess()\n    \n    def _preprocess(self):\n        \"\"\"Protected method - internal helper, but subclasses can override.\"\"\"\n        return [x * 2 for x in self.data]\n    \n    def __validate(self):\n        \"\"\"Private method - truly internal, not for subclasses.\"\"\"\n        return all(isinstance(x, (int, float)) for x in self.data)\n\ndp = DataProcessor([1, 2, 3])\nprint(f\"Public data: {dp.data}\")\nprint(f\"Protected _cache: {dp._cache}\")  # Works but discouraged\n# print(dp.__secret)  # AttributeError!\nprint(f\"Mangled name: {dp._DataProcessor__secret}\")  # How to access if needed",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary><b>Q: When should you use `_protected` vs `__private`?</b></summary>\n\n**A:**\n- **`_protected`**: Use for internal methods that subclasses might need to override. It's a convention saying \"internal, but accessible.\"\n\n- **`__private`**: Use when you truly want to prevent accidental override in subclasses. Python mangles the name to `_ClassName__method`, making it harder (but not impossible) to access.\n\n**In practice:** Most Python code uses `_protected`. Use `__private` sparingly.\n</details>"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6.3 Dunder Methods\n\nDunder (double underscore) methods let you customise how objects behave."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "class Tensor:\n    \"\"\"A simple tensor class demonstrating dunder methods.\"\"\"\n    \n    def __init__(self, data: list):\n        self.data = np.array(data)\n    \n    def __repr__(self) -> str:\n        \"\"\"For developers - unambiguous representation.\"\"\"\n        return f\"Tensor(shape={self.data.shape}, dtype={self.data.dtype})\"\n    \n    def __str__(self) -> str:\n        \"\"\"For users - readable representation.\"\"\"\n        return f\"Tensor with shape {self.data.shape}\"\n    \n    def __len__(self) -> int:\n        \"\"\"Enable len(tensor).\"\"\"\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        \"\"\"Enable tensor[idx].\"\"\"\n        return self.data[idx]\n    \n    def __call__(self, x):\n        \"\"\"Enable tensor(x) - used heavily in PyTorch!\"\"\"\n        return self.data @ x\n\nt = Tensor([[1, 2], [3, 4]])\nprint(f\"repr: {repr(t)}\")\nprint(f\"str: {str(t)}\")\nprint(f\"len: {len(t)}\")\nprint(f\"t[0]: {t[0]}\")\nprint(f\"t([1, 1]): {t(np.array([1, 1]))}\")  # Callable!",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary><b>Q: Why does PyTorch use `__call__` for the forward pass?</b></summary>\n\n**A:** In PyTorch, `model(x)` calls `model.__call__(x)`, which internally calls `model.forward(x)` but also handles:\n- Hooks (callbacks before/after forward)\n- Gradient tracking setup\n- Module state management\n\nThis is why you define `forward()` but call `model(x)`, not `model.forward(x)`.\n</details>"
  },
  {
   "cell_type": "markdown",
   "source": "## 6.5 Inheritance (Essential for PyTorch)\n\nPyTorch's `nn.Module` uses inheritance heavily. You'll subclass it for every model.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "<details>\n<summary><b>Q: Why do we call `super().__init__()` in subclasses?</b></summary>\n\n**A:** `super().__init__()` calls the parent class's `__init__` method, ensuring proper initialisation of inherited attributes. Without it:\n\n```python\nclass Linear(Module):\n    def __init__(self, in_features, out_features):\n        # WRONG: forgot super().__init__()\n        self.weight = ...\n        \nlayer = Linear(10, 5)\nprint(layer.training)  # AttributeError! .training was never set\n```\n\nIn PyTorch, forgetting `super().__init__()` is a common bug that breaks module registration, parameter tracking, and device movement.\n</details>",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Simplified nn.Module-like base class\nclass Module:\n    \"\"\"Base class demonstrating PyTorch's Module pattern.\"\"\"\n    \n    def __init__(self):\n        self._modules = {}\n        self.training = True\n    \n    def __call__(self, x):\n        \"\"\"When you call model(x), this runs.\"\"\"\n        return self.forward(x)\n    \n    def forward(self, x):\n        \"\"\"Subclasses MUST override this.\"\"\"\n        raise NotImplementedError(\"Subclasses must implement forward()\")\n    \n    def train(self, mode: bool = True):\n        self.training = mode\n        return self\n    \n    def eval(self):\n        return self.train(False)\n\n\n# Subclass: A simple linear layer\nclass Linear(Module):\n    \"\"\"Linear layer: y = x @ W + b\"\"\"\n    \n    def __init__(self, in_features: int, out_features: int):\n        super().__init__()  # Call parent's __init__\n        self.weight = np.random.randn(in_features, out_features) * 0.01\n        self.bias = np.zeros(out_features)\n    \n    def forward(self, x: np.ndarray) -> np.ndarray:\n        return x @ self.weight + self.bias  # Broadcasting!\n\n\n# Subclass: A two-layer network\nclass TwoLayerNet(Module):\n    \"\"\"Network that composes multiple layers.\"\"\"\n    \n    def __init__(self, input_size: int, hidden_size: int, output_size: int):\n        super().__init__()\n        self.fc1 = Linear(input_size, hidden_size)\n        self.fc2 = Linear(hidden_size, output_size)\n    \n    def forward(self, x: np.ndarray) -> np.ndarray:\n        x = self.fc1(x)           # Note: uses __call__, not .forward()\n        x = np.maximum(0, x)      # ReLU activation\n        x = self.fc2(x)\n        return x\n\n\n# Usage - this is exactly how you'll use PyTorch!\nmodel = TwoLayerNet(784, 128, 10)\nx = np.random.randn(32, 784)\noutput = model(x)  # Calls __call__ -> forward\nprint(f\"Input: {x.shape} -> Output: {output.shape}\")\nprint(f\"Training mode: {model.training}\")\nmodel.eval()\nprint(f\"After eval(): {model.training}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6.4 Decorators"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "class Model:\n    def __init__(self, name: str):\n        self._name = name\n        self._is_training = True\n    \n    @property\n    def name(self) -> str:\n        \"\"\"Property decorator - access like an attribute.\"\"\"\n        return self._name\n    \n    @property\n    def is_training(self) -> bool:\n        return self._is_training\n    \n    @is_training.setter\n    def is_training(self, value: bool):\n        \"\"\"Setter for property.\"\"\"\n        self._is_training = value\n        print(f\"Training mode: {value}\")\n    \n    @staticmethod\n    def count_parameters(weights: dict) -> int:\n        \"\"\"Static method - doesn't need self.\"\"\"\n        return sum(w.size for w in weights.values())\n    \n    @classmethod\n    def from_config(cls, config: dict):\n        \"\"\"Class method - alternative constructor.\"\"\"\n        return cls(name=config.get(\"name\", \"unnamed\"))\n\n# Usage\nm = Model(\"MyModel\")\nprint(f\"Name: {m.name}\")  # Property access\nm.is_training = False     # Property setter\n\nm2 = Model.from_config({\"name\": \"ConfigModel\"})  # Classmethod\nprint(f\"From config: {m2.name}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# Part 7: sklearn & Linear Regression\n\nBefore neural networks, understand classical ML. Linear regression is the foundation.\n\n---\n\n## 7.1 Train/Test Split"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "from sklearn.model_selection import train_test_split\n\n# Generate synthetic data\nnp.random.seed(42)\nX = np.random.randn(200, 1) * 2\ny = 3 * X.squeeze() + 2 + np.random.randn(200) * 0.8\n\n# Split: 80% train, 20% test\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\nprint(f\"Training set: {X_train.shape[0]} samples\")\nprint(f\"Test set: {X_test.shape[0]} samples\")\n\n# Visualise\nplt.figure(figsize=(8, 5))\nplt.scatter(X_train, y_train, alpha=0.5, label='Train')\nplt.scatter(X_test, y_test, alpha=0.5, label='Test')\nplt.xlabel('X')\nplt.ylabel('y')\nplt.title('Train/Test Split')\nplt.legend()\nplt.show()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary><b>Q: Why do we split data into train and test sets?</b></summary>\n\n**A:** To evaluate **generalisation** - how well the model performs on unseen data.\n\n- **Training set**: Used to fit model parameters\n- **Test set**: Held out completely, used only for final evaluation\n\nIf we evaluated on training data, we'd overestimate performance because the model has \"memorised\" those examples. This is called **overfitting**.\n\n**Common splits:** 80/20 or 70/30 for train/test.\n</details>"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7.2 Linear Regression with sklearn"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Fit model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Learned parameters\nprint(f\"Learned: y = {model.coef_[0]:.3f}x + {model.intercept_:.3f}\")\nprint(f\"True:    y = 3.000x + 2.000\")\n\n# Predictions\ny_pred_train = model.predict(X_train)\ny_pred_test = model.predict(X_test)\n\n# Evaluate\nprint(f\"\\nTrain MSE: {mean_squared_error(y_train, y_pred_train):.4f}\")\nprint(f\"Test MSE:  {mean_squared_error(y_test, y_pred_test):.4f}\")\nprint(f\"Test R\u00b2:   {r2_score(y_test, y_pred_test):.4f}\")\n\n# Plot fit\nplt.figure(figsize=(8, 5))\nplt.scatter(X_test, y_test, alpha=0.5, label='Test data')\nX_line = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)\nplt.plot(X_line, model.predict(X_line), colour='red', linewidth=2, label='Fitted line')\nplt.xlabel('X')\nplt.ylabel('y')\nplt.title('Linear Regression Fit')\nplt.legend()\nplt.show()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7.3 Linear Regression from Scratch\n\nImplementing gradient descent - the same algorithm that trains neural networks!"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Mathematical Derivation\n\nBefore implementing, let's derive the gradient descent update rules.\n\n<details>\n<summary><b>Deep Dive: Deriving MSE Gradients</b></summary>\n\nFor linear regression with model $\\hat{y} = wx + b$, the Mean Squared Error loss is:\n\n$$L = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2 = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - wx_i - b)^2$$\n\n**Gradient with respect to $w$:**\n\nUsing the chain rule:\n$$\\frac{\\partial L}{\\partial w} = \\frac{1}{n}\\sum_{i=1}^{n} 2(y_i - wx_i - b) \\cdot (-x_i) = -\\frac{2}{n}\\sum_{i=1}^{n} x_i(y_i - \\hat{y}_i)$$\n\n**Gradient with respect to $b$:**\n$$\\frac{\\partial L}{\\partial b} = \\frac{1}{n}\\sum_{i=1}^{n} 2(y_i - wx_i - b) \\cdot (-1) = -\\frac{2}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)$$\n\n**Update rule:** Move in the *opposite* direction of the gradient (downhill):\n$$w_{\\text{new}} = w_{\\text{old}} - \\alpha \\frac{\\partial L}{\\partial w}$$\n$$b_{\\text{new}} = b_{\\text{old}} - \\alpha \\frac{\\partial L}{\\partial b}$$\n\nwhere $\\alpha$ is the learning rate.\n</details>"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "def linear_regression_gd(X, y, lr=0.1, epochs=100):\n    \"\"\"\n    Train linear regression using gradient descent.\n    \n    Args:\n        X: Features, shape (n_samples, 1)\n        y: Targets, shape (n_samples,)\n        lr: Learning rate\n        epochs: Number of iterations\n    \n    Returns:\n        w, b: Learned parameters\n        history: Loss at each epoch\n    \"\"\"\n    # Initialise parameters\n    w = 0.0\n    b = 0.0\n    n = len(y)\n    history = []\n    \n    X_flat = X.squeeze()  # Shape: (n_samples,)\n    \n    for epoch in range(epochs):\n        # Forward pass: predictions\n        y_pred = w * X_flat + b\n        \n        # Compute loss (MSE)\n        loss = np.mean((y - y_pred) ** 2)\n        history.append(loss)\n        \n        # Compute gradients (partial derivatives of MSE)\n        # d(MSE)/dw = -2/n * sum(X * (y - y_pred))\n        # d(MSE)/db = -2/n * sum(y - y_pred)\n        dw = (-2/n) * np.sum(X_flat * (y - y_pred))\n        db = (-2/n) * np.sum(y - y_pred)\n        \n        # Update parameters (gradient descent step)\n        w = w - lr * dw\n        b = b - lr * db\n        \n        if epoch % 20 == 0:\n            print(f\"Epoch {epoch:3d}: Loss = {loss:.4f}, w = {w:.3f}, b = {b:.3f}\")\n    \n    return w, b, history\n\n# Train from scratch\nw, b, history = linear_regression_gd(X_train, y_train, lr=0.1, epochs=100)\n\nprint(f\"\\nFinal: y = {w:.3f}x + {b:.3f}\")\nprint(f\"sklearn: y = {model.coef_[0]:.3f}x + {model.intercept_:.3f}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Visualise gradient descent\nfig, axes = plt.subplots(1, 2, figsize=(12, 4))\n\n# Loss curve\naxes[0].plot(history)\naxes[0].set_xlabel('Epoch')\naxes[0].set_ylabel('MSE Loss')\naxes[0].set_title('Gradient Descent Convergence')\naxes[0].grid(True, alpha=0.3)\n\n# Compare fits\naxes[1].scatter(X_test, y_test, alpha=0.5, label='Test data')\nX_line = np.linspace(X.min(), X.max(), 100)\naxes[1].plot(X_line, w * X_line + b, colour='red', linewidth=2, label=f'GD: y={w:.2f}x+{b:.2f}')\naxes[1].plot(X_line, model.coef_[0] * X_line + model.intercept_, \n             colour='green', linewidth=2, linestyle='--', label='sklearn')\naxes[1].set_xlabel('X')\naxes[1].set_ylabel('y')\naxes[1].set_title('Comparison: Gradient Descent vs sklearn')\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary><b>Q: What happens if learning rate is too high or too low?</b></summary>\n\n**A:**\n- **Too high**: Loss oscillates or diverges (explodes to infinity). The steps are too big and overshoot the minimum.\n\n- **Too low**: Converges very slowly. May get stuck or take forever to train.\n\n**Try it**: Change `lr=0.1` to `lr=0.01` (slow) or `lr=1.0` (unstable) and observe.\n\n**Rule of thumb**: Start with lr=0.01 or 0.001 for neural networks. Use learning rate schedulers for better results.\n</details>"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7.4 Polynomial Features & Overfitting"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "from sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import make_pipeline\n\n# Generate nonlinear data\nnp.random.seed(42)\nX_poly = np.random.uniform(-3, 3, 50).reshape(-1, 1)\ny_poly = 0.5 * X_poly.squeeze()**2 - X_poly.squeeze() + 2 + np.random.randn(50) * 0.5\n\nX_train_p, X_test_p, y_train_p, y_test_p = train_test_split(X_poly, y_poly, test_size=0.3, random_state=42)\n\n# Fit models of different complexity\ndegrees = [1, 3, 15]\nfig, axes = plt.subplots(1, 3, figsize=(15, 4))\n\nX_plot = np.linspace(-3.5, 3.5, 100).reshape(-1, 1)\n\nfor ax, degree in zip(axes, degrees):\n    # Create polynomial pipeline\n    model = make_pipeline(\n        PolynomialFeatures(degree),\n        LinearRegression()\n    )\n    model.fit(X_train_p, y_train_p)\n    \n    # Evaluate\n    train_mse = mean_squared_error(y_train_p, model.predict(X_train_p))\n    test_mse = mean_squared_error(y_test_p, model.predict(X_test_p))\n    \n    # Plot\n    ax.scatter(X_train_p, y_train_p, alpha=0.6, label='Train')\n    ax.scatter(X_test_p, y_test_p, alpha=0.6, label='Test')\n    ax.plot(X_plot, model.predict(X_plot), colour='red', linewidth=2)\n    ax.set_xlabel('X')\n    ax.set_ylabel('y')\n    ax.set_title(f'Degree {degree}\\nTrain MSE: {train_mse:.2f}, Test MSE: {test_mse:.2f}')\n    ax.legend()\n    ax.set_ylim(-5, 15)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Observe: Degree 15 has LOW train error but HIGH test error = OVERFITTING\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary><b>Q: How do you detect overfitting?</b></summary>\n\n**A:** Compare train vs test performance:\n\n| Scenario | Train Error | Test Error | Diagnosis |\n|----------|------------|-----------|-----------|\n| Low | Low | Good fit |\n| Low | High | **Overfitting** |\n| High | High | Underfitting |\n\n**Solutions for overfitting:**\n1. More training data\n2. Simpler model (fewer parameters)\n3. Regularization (L1/L2)\n4. Early stopping\n5. Dropout (for neural networks)\n</details>"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7.5 Regularization Preview"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "from sklearn.linear_model import Ridge, Lasso\n\n# Compare regularized models on degree-15 polynomial\nfig, axes = plt.subplots(1, 3, figsize=(15, 4))\n\nmodels = [\n    ('No Regularization', make_pipeline(PolynomialFeatures(15), LinearRegression())),\n    ('Ridge (L2)', make_pipeline(PolynomialFeatures(15), Ridge(alpha=1.0))),\n    ('Lasso (L1)', make_pipeline(PolynomialFeatures(15), Lasso(alpha=0.1))),\n]\n\nfor ax, (name, model) in zip(axes, models):\n    model.fit(X_train_p, y_train_p)\n    \n    train_mse = mean_squared_error(y_train_p, model.predict(X_train_p))\n    test_mse = mean_squared_error(y_test_p, model.predict(X_test_p))\n    \n    ax.scatter(X_train_p, y_train_p, alpha=0.6, label='Train')\n    ax.scatter(X_test_p, y_test_p, alpha=0.6, label='Test')\n    ax.plot(X_plot, model.predict(X_plot), colour='red', linewidth=2)\n    ax.set_xlabel('X')\n    ax.set_ylabel('y')\n    ax.set_title(f'{name}\\nTrain: {train_mse:.2f}, Test: {test_mse:.2f}')\n    ax.legend()\n    ax.set_ylim(-5, 15)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Ridge/Lasso add penalty terms to prevent overfitting:\")\nprint(\"  Ridge: penalizes large weights (L2 norm)\")\nprint(\"  Lasso: promotes sparsity (L1 norm)\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# Part 8: Practical Patterns\n\n---\n\n## 8.1 Generators & Iterators\n\nGenerators are crucial for memory-efficient data loading."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Generator function - uses yield\ndef count_up_to(n: int):\n    \"\"\"Generate numbers from 0 to n-1.\"\"\"\n    i = 0\n    while i < n:\n        yield i  # Pauses here, returns value\n        i += 1\n\n# Usage\nfor num in count_up_to(5):\n    print(num, end=\" \")\nprint()\n\n# Generator expression (like list comprehension but lazy)\nsquares_gen = (x**2 for x in range(1000000))  # No memory allocated yet!\nprint(f\"Generator: {squares_gen}\")\nprint(f\"First 5: {[next(squares_gen) for _ in range(5)]}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Why generators matter for DL: memory efficiency\nimport sys\n\n# List stores all values in memory\nbig_list = [i**2 for i in range(1000000)]\nprint(f\"List size: {sys.getsizeof(big_list) / 1e6:.1f} MB\")\n\n# Generator computes on-demand\ndef big_gen():\n    for i in range(1000000):\n        yield i**2\n\ngen = big_gen()\nprint(f\"Generator size: {sys.getsizeof(gen)} bytes\")\n\n# DataLoader-style batching\ndef batch_generator(data: list, batch_size: int):\n    \"\"\"Yield batches from data.\"\"\"\n    for i in range(0, len(data), batch_size):\n        yield data[i:i + batch_size]\n\ndata = list(range(100))\nfor batch in batch_generator(data, batch_size=32):\n    print(f\"Batch: {batch[:3]}... (size {len(batch)})\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary><b>Q: When should you use a generator vs a list?</b></summary>\n\n**A:**\n- **Generator**: When data is large, you only need one pass, or values are computed on-demand\n- **List**: When you need random access, multiple passes, or the data is small\n\n**DataLoaders use generators** because:\n1. Training data is often huge (can't fit in RAM)\n2. You only need one batch at a time\n3. Data can be augmented on-the-fly\n</details>"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8.2 File I/O with Pathlib"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "from pathlib import Path\n\n# Create paths (cross-platform!)\ndata_dir = Path(\"data\")\nmodel_path = data_dir / \"models\" / \"best.pt\"\n\nprint(f\"Path: {model_path}\")\nprint(f\"Parent: {model_path.parent}\")\nprint(f\"Name: {model_path.name}\")\nprint(f\"Stem: {model_path.stem}\")\nprint(f\"Suffix: {model_path.suffix}\")\n\n# Check existence\nprint(f\"\\nExists: {model_path.exists()}\")\nprint(f\"Is file: {model_path.is_file()}\")\n\n# Find files\ncurrent = Path(\".\")\nprint(f\"\\nPython files in current dir: {list(current.glob('*.py'))[:3]}\")\nprint(f\"All .ipynb (recursive): {list(current.glob('**/*.ipynb'))[:3]}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8.3 Debugging Strategies"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# 1. Print debugging with f-strings\ndef debug_forward(x, W):\n    print(f\"DEBUG: x.shape={x.shape}, W.shape={W.shape}\")\n    result = x @ W\n    print(f\"DEBUG: result.shape={result.shape}\")\n    return result\n\n# 2. Assertions - catch bugs early\ndef normalize(x: np.ndarray) -> np.ndarray:\n    assert x.ndim == 2, f\"Expected 2D array, got {x.ndim}D\"\n    assert x.shape[0] > 0, \"Empty array\"\n    return (x - x.mean(axis=0)) / (x.std(axis=0) + 1e-8)\n\n# 3. Shape annotations in comments\ndef attention(Q, K, V):\n    # Q: (batch, heads, seq_len, d_k)\n    # K: (batch, heads, seq_len, d_k)\n    # V: (batch, heads, seq_len, d_v)\n    \n    scores = Q @ K.transpose(-2, -1)  # (batch, heads, seq_len, seq_len)\n    weights = scores  # Simplified - normally softmax\n    output = weights @ V  # (batch, heads, seq_len, d_v)\n    return output\n\n# Test\nx = np.random.randn(32, 784)\nW = np.random.randn(784, 128)\ny = debug_forward(x, W)\nz = normalize(x)\nprint(f\"\\nNormalized shape: {z.shape}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# Part 9: Summary & Capstone\n\n---\n\n## Key Takeaways\n\n### Python Foundations\n- Use **type hints** for self-documenting code\n- Use **comprehensions** for building collections\n- Use **context managers** (`with`) for resource management\n\n### NumPy\n- **Vectorize** operations - avoid Python loops\n- **Broadcasting** aligns shapes from the right\n- **axis=0** collapses rows, **axis=1** collapses columns\n\n### Data Handling\n- **Pandas** for loading and preprocessing tabular data\n- Always check for **missing values** and handle appropriately\n- **Scale features** before training ML models\n\n### Machine Learning Basics\n- Always **split** data into train/test sets\n- **MSE** and **R\u00b2** for regression evaluation\n- Watch for **overfitting**: low train error, high test error\n- **Regularization** (Ridge/Lasso) prevents overfitting\n\n### OOP for DL\n- **`__call__`** makes objects callable (used by `nn.Module`)\n- **Inheritance** is fundamental to PyTorch model building\n\n### Practical Patterns\n- **Generators** for memory-efficient iteration (DataLoaders!)\n- **Pathlib** for cross-platform file paths"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Self-Assessment Checklist\n\nBefore proceeding to Lab 2, you should be able to:\n\n- [ ] Write a function with type hints and a Google-style docstring\n- [ ] Predict the output shape of broadcasting `(3,1) + (4,)`\n- [ ] Load a CSV file with pandas and handle missing values\n- [ ] Split data into train/test sets using sklearn\n- [ ] Train a linear regression model and compute MSE\n- [ ] Explain why high train accuracy + low test accuracy = overfitting\n- [ ] Explain why `__call__` is used in PyTorch modules\n- [ ] Write a generator function with `yield`"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Capstone Exercise: End-to-End ML Pipeline\n\nBuild a complete pipeline from data loading to model evaluation:"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Capstone Exercise: Complete the pipeline\n\nclass MLPipeline:\n    \"\"\"\n    End-to-end ML pipeline.\n    \n    TODO: Implement the following methods:\n    1. load_data: Load wine dataset from sklearn\n    2. preprocess: Handle missing values, scale features\n    3. split: Train/test split\n    4. train: Fit a Ridge regression model\n    5. evaluate: Return MSE and R\u00b2 on test set\n    \"\"\"\n    \n    def __init__(self):\n        self.scaler = None\n        self.model = None\n        self.X_train = None\n        self.X_test = None\n        self.y_train = None\n        self.y_test = None\n    \n    def load_data(self):\n        # TODO: Load wine dataset, use first feature as target for regression\n        pass\n    \n    def preprocess(self, X):\n        # TODO: Scale features using StandardScaler\n        # Remember: fit on train, transform on both train and test\n        pass\n    \n    def split(self, X, y, test_size=0.2):\n        # TODO: Split into train/test\n        pass\n    \n    def train(self):\n        # TODO: Fit Ridge regression\n        pass\n    \n    def evaluate(self):\n        # TODO: Return dict with 'mse' and 'r2' on test set\n        pass\n    \n    def run(self):\n        \"\"\"Run the full pipeline.\"\"\"\n        X, y = self.load_data()\n        self.split(X, y)\n        self.X_train = self.preprocess(self.X_train)\n        self.X_test = self.preprocess(self.X_test)\n        self.train()\n        return self.evaluate()\n\n# Test your implementation:\n# pipeline = MLPipeline()\n# results = pipeline.run()\n# print(f\"Test MSE: {results['mse']:.4f}\")\n# print(f\"Test R\u00b2: {results['r2']:.4f}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary><b>Solution</b></summary>\n\n```python\nclass MLPipeline:\n    def __init__(self):\n        self.scaler = StandardScaler()\n        self.model = Ridge(alpha=1.0)\n        self.X_train = None\n        self.X_test = None\n        self.y_train = None\n        self.y_test = None\n        self._fitted = False\n    \n    def load_data(self):\n        wine = load_wine()\n        X = wine.data[:, 1:]  # Features (all but first)\n        y = wine.data[:, 0]   # Target (first column: alcohol)\n        return X, y\n    \n    def preprocess(self, X):\n        if not self._fitted:\n            self._fitted = True\n            return self.scaler.fit_transform(X)\n        return self.scaler.transform(X)\n    \n    def split(self, X, y, test_size=0.2):\n        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n            X, y, test_size=test_size, random_state=42\n        )\n    \n    def train(self):\n        self.model.fit(self.X_train, self.y_train)\n    \n    def evaluate(self):\n        y_pred = self.model.predict(self.X_test)\n        return {\n            'mse': mean_squared_error(self.y_test, y_pred),\n            'r2': r2_score(self.y_test, y_pred)\n        }\n```\n</details>"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# Part 10: Software Engineering Essentials\n\nProfessional data science requires more than just modeling skills. This section covers essential tools and practices.\n\n> **Prerequisite Course**: For data structures and algorithms foundations, see the [DSA Lab Course](https://github.com/henrycgbaker/data-structures-algorithms-lab-2025-TEACHING).\n\n---\n\n## 10.1 Python Package Management"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Virtual Environments\n\nAlways use virtual environments to isolate project dependencies:\n\n```bash\n# Using venv (built-in)\npython -m venv .venv\nsource .venv/bin/activate  # Linux/Mac\n.venv\\Scripts\\activate   # Windows\n\n# Using conda\nconda create -n myproject python=3.10\nconda activate myproject\n```\n\n### requirements.txt vs pyproject.toml\n\n**requirements.txt** (traditional):\n```\nnumpy>=1.20.0\npandas>=1.3.0\ntorch>=2.0.0\n```\n\n**pyproject.toml** (modern, recommended):\n```toml\n[project]\nname = \"my-dl-project\"\nversion = \"0.1.0\"\nrequires-python = \">=3.10\"\ndependencies = [\n    \"numpy>=1.20.0\",\n    \"pandas>=1.3.0\",\n    \"torch>=2.0.0\",\n]\n\n[project.optional-dependencies]\ndev = [\"pytest\", \"ruff\", \"mypy\"]\n```"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Poetry (Recommended for Projects)\n\n[Poetry](https://python-poetry.org/) provides dependency management and packaging:\n\n```bash\n# Install poetry\ncurl -sSL https://install.python-poetry.org | python3 -\n\n# Create new project\npoetry new my-project\ncd my-project\n\n# Add dependencies\npoetry add numpy pandas torch\npoetry add --group dev pytest ruff\n\n# Install all dependencies\npoetry install\n\n# Run commands in virtual environment\npoetry run python train.py\npoetry run pytest\n\n# Export to requirements.txt (for deployment)\npoetry export -f requirements.txt --output requirements.txt\n```\n\n**Why Poetry?**\n- Lock file ensures reproducible builds\n- Separates dev and production dependencies\n- Handles version conflicts automatically\n- Modern pyproject.toml format"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary><b>Q: When should you use pip vs conda vs poetry?</b></summary>\n\n**A:**\n| Tool | Best For |\n|------|----------|\n| **pip** | Simple scripts, quick prototypes |\n| **conda** | Scientific computing, GPU libraries, cross-language deps |\n| **poetry** | Production projects, packages you'll distribute |\n\n**Rule of thumb**: \n- Colab/quick experiments \u2192 pip\n- Complex ML environments \u2192 conda\n- Serious projects \u2192 poetry\n</details>"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 10.2 Code Quality & Pre-commit Hooks"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Pre-commit hooks run checks automatically before each commit\n# Install: pip install pre-commit\n\n# Example .pre-commit-config.yaml:\npre_commit_config = \"\"\"\nrepos:\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    rev: v0.1.6\n    hooks:\n      - id: ruff          # Linting\n        args: [--fix]\n      - id: ruff-format   # Formatting\n  \n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.5.0\n    hooks:\n      - id: trailing-whitespace\n      - id: end-of-file-fixer\n      - id: check-yaml\n      - id: check-added-large-files\n\"\"\"\n\nprint(\"Save this as .pre-commit-config.yaml in your repo root\")\nprint(\"Then run: pre-commit install\")\nprint(\"Now every 'git commit' will auto-format and lint your code!\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Ruff: Modern Python Linter\n\n[Ruff](https://github.com/astral-sh/ruff) is extremely fast and replaces multiple tools:\n\n```bash\n# Install\npip install ruff\n\n# Lint (check for issues)\nruff check .\n\n# Fix auto-fixable issues\nruff check --fix .\n\n# Format (like black)\nruff format .\n```\n\n**pyproject.toml configuration:**\n```toml\n[tool.ruff]\nline-length = 100\ntarget-version = \"py310\"\n\n[tool.ruff.lint]\nselect = [\"E\", \"F\", \"I\", \"UP\"]  # Error, pyflakes, isort, pyupgrade\nignore = [\"E501\"]  # Line too long (handled by formatter)\n```"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 10.3 GitHub Actions (CI/CD)\n\nAutomatically run tests and checks on every push:\n\n```yaml\n# .github/workflows/ci.yml\nname: CI\n\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      \n      - name: Set up Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: '3.10'\n      \n      - name: Install dependencies\n        run: |\n          pip install -r requirements.txt\n          pip install pytest ruff\n      \n      - name: Lint with ruff\n        run: ruff check .\n      \n      - name: Run tests\n        run: pytest tests/\n```\n\nThis ensures:\n- Every PR is automatically tested\n- Code style is enforced\n- Broken code can't be merged"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary><b>Q: Why copy requirements.txt before copying code in Dockerfile?</b></summary>\n\n**A:** Docker caches each layer. If you copy code first, ANY code change invalidates the cache for `pip install`. By copying requirements.txt first:\n- Requirements layer is cached if dependencies are unchanged\n- Code changes only rebuild the final copy layer\n\nThis can save minutes on each build when dependencies are stable.\n</details>\n\n<details>\n<summary><b>Q: What's the difference between `poetry install` and `pip install -r requirements.txt`?</b></summary>\n\n**A:**\n- **`poetry install`**: Uses lock file (`poetry.lock`) for exact versions. Creates isolated virtual environment. Handles dependency resolution.\n\n- **`pip install -r`**: Uses version ranges from requirements.txt. May get different versions on different machines. No built-in environment management.\n\nPoetry is more reproducible; pip is simpler for quick setups.\n</details>"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 10.4 Docker Basics\n\nDocker containers ensure your code runs the same everywhere.\n\n> **Full Docker Course**: See [DS Hub Docker Guide](https://github.com/hertie-data-science-lab/ds01-hub/tree/main)\n\n### Essential Dockerfile for ML\n\n```dockerfile\n# Use official Python image\nFROM python:3.10-slim\n\n# Set working directory\nWORKDIR /app\n\n# Copy requirements first (for caching)\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Copy code\nCOPY . .\n\n# Run training script\nCMD [\"python\", \"train.py\"]\n```\n\n### Common Commands\n\n```bash\n# Build image\ndocker build -t my-ml-project .\n\n# Run container\ndocker run my-ml-project\n\n# Run with GPU (NVIDIA)\ndocker run --gpus all my-ml-project\n\n# Interactive shell\ndocker run -it my-ml-project /bin/bash\n\n# Mount local directory\ndocker run -v $(pwd)/data:/app/data my-ml-project\n```"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Docker Compose for Multi-Container Apps\n\n```yaml\n# docker-compose.yml\nversion: '3.8'\nservices:\n  training:\n    build: .\n    volumes:\n      - ./data:/app/data\n      - ./models:/app/models\n    deploy:\n      resources:\n        reservations:\n          devices:\n            - driver: nvidia\n              count: 1\n              capabilities: [gpu]\n  \n  tensorboard:\n    image: tensorflow/tensorflow\n    ports:\n      - \"6006:6006\"\n    volumes:\n      - ./logs:/logs\n    command: tensorboard --logdir=/logs --host=0.0.0.0\n```\n\n```bash\n# Start all services\ndocker-compose up\n\n# Run in background\ndocker-compose up -d\n\n# Stop all\ndocker-compose down\n```"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary><b>Q: When should you use Docker for ML projects?</b></summary>\n\n**A:** Use Docker when:\n- **Reproducibility matters**: Ensure exact same environment\n- **Deployment**: Serving models in production\n- **Collaboration**: Share exact environments with team\n- **GPU clusters**: Many HPC systems require containers\n\n**Skip Docker when:**\n- Quick experiments in Colab\n- Simple scripts with few dependencies\n- Learning/prototyping phase\n\n**Rule**: Start without Docker, add it when you need reproducibility or deployment.\n</details>"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 10.5 Project Structure\n\nRecommended structure for ML projects:\n\n```\nmy-ml-project/\n\u251c\u2500\u2500 .github/\n\u2502   \u2514\u2500\u2500 workflows/\n\u2502       \u2514\u2500\u2500 ci.yml          # GitHub Actions\n\u251c\u2500\u2500 data/\n\u2502   \u251c\u2500\u2500 raw/                # Original data (gitignored)\n\u2502   \u2514\u2500\u2500 processed/          # Cleaned data\n\u251c\u2500\u2500 models/                 # Saved model checkpoints\n\u251c\u2500\u2500 notebooks/              # Jupyter notebooks for exploration\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 data.py            # Data loading/preprocessing\n\u2502   \u251c\u2500\u2500 model.py           # Model architecture\n\u2502   \u251c\u2500\u2500 train.py           # Training loop\n\u2502   \u2514\u2500\u2500 evaluate.py        # Evaluation metrics\n\u251c\u2500\u2500 tests/\n\u2502   \u2514\u2500\u2500 test_model.py      # Unit tests\n\u251c\u2500\u2500 .gitignore\n\u251c\u2500\u2500 .pre-commit-config.yaml\n\u251c\u2500\u2500 pyproject.toml         # Dependencies & config\n\u251c\u2500\u2500 README.md\n\u2514\u2500\u2500 Dockerfile\n```\n\n**Key principles:**\n- Separate code (src/) from experiments (notebooks/)\n- Never commit raw data or model weights to git\n- Use pyproject.toml for all configuration\n- Write tests for critical functions"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 10.6 Further Resources\n\n### Courses & Links\n- [DSA Lab Course](https://github.com/henrycgbaker/data-structures-algorithms-lab-2025-TEACHING) - Data structures & algorithms\n- [DS Hub Docker Guide](https://github.com/hertie-data-science-lab/ds01-hub/tree/main) - Docker for data science\n- [Poetry Documentation](https://python-poetry.org/docs/)\n- [GitHub Actions Guide](https://docs.github.com/en/actions)\n- [Ruff Documentation](https://docs.astral.sh/ruff/)\n\n### Books\n- *The Good Research Code Handbook* - Patrick Mineault\n- *Software Engineering for Data Scientists* - Andrew Trevett"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## References\n\n### Python & NumPy\n1. [Python Type Hints Cheat Sheet](https://mypy.readthedocs.io/en/stable/cheat_sheet_py3.html)\n2. [NumPy Broadcasting Rules](https://numpy.org/doc/stable/user/basics.broadcasting.html)\n3. [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html)\n\n### Data Science & ML\n4. [Pandas Documentation](https://pandas.pydata.org/docs/)\n5. [sklearn User Guide](https://scikit-learn.org/stable/user_guide.html)\n6. [PyTorch nn.Module Source](https://github.com/pytorch/pytorch/blob/main/torch/nn/modules/module.py)\n\n### Software Engineering\n7. [DSA Lab Course](https://github.com/henrycgbaker/data-structures-algorithms-lab-2025-TEACHING) - Prerequisites\n8. [DS Hub Docker Guide](https://github.com/hertie-data-science-lab/ds01-hub/tree/main)\n9. [Poetry Documentation](https://python-poetry.org/docs/)\n10. [Ruff Documentation](https://docs.astral.sh/ruff/)\n11. [GitHub Actions Guide](https://docs.github.com/en/actions)\n\n---\n\n**Next:** Lab 2 - Introduction to Feedforward Neural Networks"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}